import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.tree import DecisionTreeRegressor, plot_tree

# Generate data
np.random.seed(42)
X = np.random.rand(100, 1) - 0.5
y = 3 * X[:, 0]**2 + 0.05 * np.random.randn(100)

df = pd.DataFrame()
df['X'] = X.reshape(100)
df['y'] = y

# Plot X vs y
plt.scatter(df['X'], df['y'])
plt.title('X vs y')
plt.show()

# Initial prediction
df['pred1'] = df['y'].mean()
df['res1'] = df['y'] - df['pred1']

plt.scatter(df['X'], df['y'])
plt.plot(df['X'], df['pred1'], color='red')
plt.title('Initial Prediction')
plt.show()

# Train first decision tree
tree1 = DecisionTreeRegressor(max_leaf_nodes=8)
tree1.fit(df['X'].values.reshape(100, 1), df['res1'].values)

# Visualize tree
plot_tree(tree1)
plt.show()

# Update predictions and residuals
df['pred2'] = df['pred1'] + tree1.predict(df['X'].values.reshape(100, 1))
df['res2'] = df['y'] - df['pred2']

def gradient_boost(X, y, number, lr, count=1, regs=None, foo=None):
  if regs is None:
    regs = []
  if number == 0:
    return
  else:
    if count > 1:
      y = y - regs[-1].predict(X)
    else:
      foo = y
    tree_reg = DecisionTreeRegressor(max_depth=5, random_state=42)
    tree_reg.fit(X, y)
    regs.append(tree_reg)
    x1 = np.linspace(-0.5, 0.5, 500)
    y_pred = sum(lr * regressor.predict(x1.reshape(-1, 1)) for regressor in regs)
    print(f"Iteration: {count}")
    plt.figure()
    plt.plot(x1, y_pred, linewidth=2)
    plt.scatter(X[:, 0], foo, color="r", s=10)
    plt.title(f"Boosting Iteration {count}")
    plt.show()
    gradient_boost(X, y, number - 1, lr, count + 1, regs, foo=foo)

np.random.seed(42)
X = np.random.rand(100, 1) - 0.5
y = 3 * X[:, 0]**2 + 0.05 * np.random.randn(100)

gradient_boost(X, y, 5, lr=1)
